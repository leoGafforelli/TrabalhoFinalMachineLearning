# -*- coding: utf-8 -*-
"""TrabalhoFinalMachineLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kGu6YsaHSgQqJhBgp_zikgVQbsy0J5jc

Pré-processamento dos dados
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

dados = pd.read_csv('dadosDiego.csv')

dados_verificados = dados.copy()

print("Registros do dataset:")
print(dados_verificados.head(20))

print("\nInformações gerais:")
print(dados_verificados.info())

print("\nValores ausentes por coluna:")
print(dados_verificados.isnull().sum())

print("Resumo estatístico das variáveis numéricas:")
print(dados_verificados.describe())

plt.figure(figsize=(10, 6))
sns.histplot(dados_verificados['Março'], kde=True, bins=30, color='blue', label='Março')
sns.histplot(dados_verificados['Abril'], kde=True, bins=30, color='orange', label='Abril')
plt.title('Distribuição das Vendas em Março e Abril')
plt.xlabel('Quantidade de Vendas')
plt.ylabel('Frequência')
plt.legend()
plt.show()

dados_numericos = dados_verificados.select_dtypes(include=['float64', 'int64'])

plt.figure(figsize=(8, 6))
sns.heatmap(dados_numericos.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Mapa de Correlação entre as Variáveis')
plt.show()

valores_ausentes = dados_verificados.isnull().sum().sum()
if valores_ausentes > 0:
  print(f"\nTratando {valores_ausentes} valores ausentes.")
  dados_tratados = dados_verificados.fillna(0)
else:
  dados_tratados = dados_verificados

from sklearn.preprocessing import MinMaxScaler

normalizador = MinMaxScaler()
colunas_para_normalizar = ['Março', 'Abril']
dados_normalizados = dados_tratados.copy()
dados_normalizados[colunas_para_normalizar] = normalizador.fit_transform(
    dados_tratados[colunas_para_normalizar]
)

print("\nRegistros após normalização:")
print(dados_normalizados.head(20))

"""Machine Learning"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler

dados_verificados['Target'] = (dados_verificados['Diferenca'] > 0).astype(int)

X = dados_verificados[['Março', 'Abril']]
y = dados_verificados['Target']

X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_treino_normalizado = scaler.fit_transform(X_treino)
X_teste_normalizado = scaler.transform(X_teste)

modelo = RandomForestClassifier(random_state=42)

modelo.fit(X_treino_normalizado, y_treino)

y_pred = modelo.predict(X_teste_normalizado)

print("Acurácia do Modelo:", accuracy_score(y_teste, y_pred))
print("\nRelatório de Classificação:\n", classification_report(y_teste, y_pred))

from sklearn.model_selection import GridSearchCV

parametros = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(estimator=modelo, param_grid=parametros, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_treino_normalizado, y_treino)

print("\nMelhores parâmetros encontrados:")
print(grid_search.best_params_)

modelo_ajustado = grid_search.best_estimator_
modelo_ajustado.fit(X_treino_normalizado, y_treino)

y_pred_ajustado = modelo_ajustado.predict(X_teste_normalizado)
print("\nAcurácia após ajuste de hiperparâmetros:", accuracy_score(y_teste, y_pred_ajustado))
print("\nRelatório de Classificação após ajuste:\n", classification_report(y_teste, y_pred_ajustado))

from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
    roc_curve,
    auc
)
import matplotlib.pyplot as plt

acuracia = accuracy_score(y_teste, y_pred_ajustado)
print(f"Acurácia do Modelo: {acuracia:.2f}")

print("\nRelatório de Classificação:\n", classification_report(y_teste, y_pred_ajustado))

matriz_confusao = confusion_matrix(y_teste, y_pred_ajustado)
disp = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao, display_labels=['Negativo', 'Positivo'])
disp.plot(cmap='Blues')
plt.title('Matriz de Confusão')
plt.show()

probabilidades = modelo_ajustado.predict_proba(X_teste_normalizado)[:, 1]
fpr, tpr, thresholds = roc_curve(y_teste, probabilidades)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

print(f"AUC (Área sob a curva ROC): {roc_auc:.2f}")